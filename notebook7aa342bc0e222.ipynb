{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":120569997,"sourceType":"kernelVersion"},{"sourceId":289186564,"sourceType":"kernelVersion"}],"dockerImageVersionId":31236,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-14T03:11:35.137081Z","iopub.execute_input":"2026-01-14T03:11:35.137310Z","iopub.status.idle":"2026-01-14T03:11:36.296736Z","shell.execute_reply.started":"2026-01-14T03:11:35.137286Z","shell.execute_reply":"2026-01-14T03:11:36.295941Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/AIMO3_Reference_Problems.pdf\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/sample_submission.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/aimo_3_inference_server.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/aimo_3_gateway.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/__init__.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/templates.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/relay.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/__init__.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/__init__.py\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__results__.html\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission_2.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__resultx__.html\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__notebook__.ipynb\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__output__.json\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission_1.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/custom.css\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/reference.csv\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/submission.parquet\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__results__.html\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/vllm_server.log\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__notebook__.ipynb\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__output__.json\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/custom.css\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ========== AI MATHEMATICAL OLYMPIAD - OFFLINE LEARNING SYSTEM ==========\n# This code runs completely offline and learns from practice questions\n# Then generates submission.csv with id and single-digit integer answers\n\nimport os, sys, json, re, hashlib, time, logging, multiprocessing, gc\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport torch\nimport sympy\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport wandb\n\n# ========== WANDB OFFLINE MODE ==========\n# Set to offline mode - no internet required\nwandb.init(\n    project=\"ai-mathematical-olympiad-progress-prize-3\",\n    mode=\"offline\",  # CRITICAL: Runs without internet\n    config={\n        \"competition\": \"AI Mathematical Olympiad Progress Prize 3\",\n        \"framework\": \"LightGBM + Transformers\",\n        \"task\": \"mathematical_problem_solving\",\n        \"solver_timeout\": 25,\n        \"k_folds\": 5,\n        \"lgb_n_estimators\": 50,\n        \"lgb_learning_rate\": 0.1,\n        \"offline_mode\": True\n    }\n)\n\n# ========== SETUP & PATHS ==========\nsys.path.append('/kaggle/input/ai-mathematical-olympiad-progress-prize-3')\nimport kaggle_evaluation.aimo_3_inference_server\n\nMODEL_PATH = \"/kaggle/input/all-minilm-l6-v2-tuning-model-add\"\nREF_DATA_PATH = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\"\nTEST_DATA_PATH = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv\"\nCACHE_PATH = \"/kaggle/working/aimo_cache.json\"\nSOLVER_TIMEOUT = 25 \n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"AIMO_LOGIC\")\n\nwandb.config.update({\n    \"model_path\": MODEL_PATH,\n    \"ref_data_path\": REF_DATA_PATH,\n    \"test_data_path\": TEST_DATA_PATH\n})\n\n# ========== METHOD 1: LOGICAL FEATURE EXTRACTION ==========\ndef extract_logical_features(text):\n    \"\"\"\n    METHOD: Extract mathematical domain and complexity features.\n    REASONING: Identifies problem type (modulo, geometry, algebra) and complexity\n    indicators (token count, digit density, symbol count) to guide solving strategy.\n    \"\"\"\n    text_lower = text.lower()\n    features = {\n        # Domain identification (Premise)\n        'is_mod_premise': 1 if 'modulo' in text_lower or 'mod' in text_lower else 0,\n        'is_geom_premise': 1 if any(w in text_lower for w in ['triangle', 'circle', 'radius', 'angle']) else 0,\n        'is_algebra_premise': 1 if 'equation' in text_lower or 'solve for' in text_lower else 0,\n        \n        # Complexity mapping (Analogy)\n        'token_count': len(text.split()),\n        'digit_density': len(re.findall(r'\\d', text)) / (len(text) + 1),\n        'math_symbol_count': len(re.findall(r'[\\+\\-\\*\\/\\=\\^\\<\\>\\(\\)]', text))\n    }\n    return features\n\n# ========== METHOD 2: SYMBOLIC SOLVER (DISJUNCTIVE ARGUMENT) ==========\ndef _disjunctive_logic(text, result_dict):\n    \"\"\"\n    METHOD: Disjunctive Argument Solver\n    REASONING: Either problem is Symbolic (Case A: modulo) OR Modular (Case B: equation).\n    If neither works, defaults to ML (Case C). This is faster and more accurate than pure ML.\n    \"\"\"\n    try:\n        # Case A: Modular arithmetic (e.g., \"123 \\pmod{10}\")\n        mod_match = re.search(r'(\\d+)\\s*\\\\pmod\\s*{\\s*(\\d+)\\s*}', text)\n        if mod_match:\n            result = int(mod_match.group(1)) % int(mod_match.group(2))\n            result_dict['ans'] = result % 10  # Ensure single digit\n            result_dict['method'] = 'modulo'\n            return\n\n        # Case B: Symbolic equation solving (e.g., \"$x^2 = 4$\")\n        math_match = re.search(r'\\$(.*?)\\$', text)\n        if math_match and 'x' in math_match.group(1):\n            expr = math_match.group(1).replace('^', '**').replace('=', '-')\n            sol = sympy.solve(sympy.sympify(expr))\n            if sol:\n                result = int(abs(float(sol[0].evalf()))) % 10\n                result_dict['ans'] = result\n                result_dict['method'] = 'symbolic'\n                return\n    except:\n        pass\n    result_dict['ans'] = None\n    result_dict['method'] = None\n\ndef solve_with_reasoning(text):\n    \"\"\"\n    METHOD: Timeout-protected symbolic solver\n    REASONING: Uses multiprocessing to prevent hanging on complex problems.\n    Returns single digit (0-9) answer or None if fails.\n    \"\"\"\n    manager = multiprocessing.Manager()\n    result_dict = manager.dict({'ans': None, 'method': None})\n    p = multiprocessing.Process(target=_disjunctive_logic, args=(text, result_dict))\n    p.start()\n    p.join(SOLVER_TIMEOUT)\n    if p.is_alive():\n        p.terminate()\n        return None, None\n    return result_dict['ans'], result_dict['method']\n\n# ========== METHOD 3: TRANSFORMER REASONING ENGINE ==========\nclass ReasoningEngine:\n    \"\"\"\n    METHOD: Transformer-based semantic reasoning\n    REASONING: Uses pre-trained transformer to extract semantic embeddings that capture\n    the mathematical \"reasoning\" needed. These embeddings are combined with logical features\n    to predict answers. The model learns patterns from practice problems.\n    \"\"\"\n    def __init__(self, path):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        wandb.config.update({\"device\": self.device})\n        try:\n            config = AutoConfig.from_pretrained(path)\n            if not hasattr(config, 'model_type'): \n                config.model_type = \"bert\"\n            self.tk = AutoTokenizer.from_pretrained(path)\n            self.mdl = AutoModel.from_pretrained(\n                path, \n                config=config, \n                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n            ).to(self.device)\n            self.mdl.eval()\n            self.ready = True\n            wandb.log({\"model_loaded\": 1, \"model_ready\": 1})\n        except Exception as e:\n            self.ready = False\n            wandb.log({\"model_loaded\": 0, \"model_error\": str(e)})\n\n    def get_reasoning_vector(self, text):\n        \"\"\"Extract 16-dimensional reasoning vector from problem text.\"\"\"\n        if not self.ready: \n            return np.zeros(16)\n        inputs = self.tk([text], return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n        with torch.no_grad():\n            out = self.mdl(**inputs, output_hidden_states=True)\n            return out.hidden_states[-1].mean(dim=1).cpu().float().numpy()[0, :16]\n\n# ========== GLOBAL INITIALIZATION ==========\nENGINE = ReasoningEngine(MODEL_PATH)\nLGB_MODELS = []\nMEMO = {}  # Cache for solved problems\nREASONING_LOG = []  # Store reasoning for each prediction\n\n# ========== METHOD 4: ENSEMBLE LEARNING FROM PRACTICE SET ==========\ndef train_ensemble():\n    \"\"\"\n    METHOD: K-Fold Cross-Validation Ensemble Learning\n    REASONING: \n    1. Loads practice problems from reference.csv\n    2. Extracts features: Transformer embeddings (16D) + Logical features (6D) = 22D\n    3. Trains 5 LightGBM models using 5-fold CV\n    4. Each model learns different patterns, ensemble averages reduce overfitting\n    5. Models learn to map problem features → single digit answer (0-9)\n    \"\"\"\n    if not os.path.exists(REF_DATA_PATH):\n        wandb.log({\"training_status\": \"failed\", \"reason\": \"reference_data_not_found\"})\n        return\n    \n    # Load practice problems\n    df = pd.read_csv(REF_DATA_PATH)\n    wandb.config.update({\n        \"training_samples\": len(df),\n        \"answer_min\": int(df['answer'].min()),\n        \"answer_max\": int(df['answer'].max())\n    })\n    \n    # Extract features\n    all_feats = []\n    all_answers = []\n    \n    for idx, row in df.iterrows():\n        txt = row['problem']\n        answer = int(row['answer']) % 10  # Ensure single digit\n        \n        # Combine: Transformer embeddings + Logical features\n        vec = ENGINE.get_reasoning_vector(txt)\n        log_f = extract_logical_features(txt)\n        feat_vector = np.concatenate([vec, list(log_f.values())])\n        all_feats.append(feat_vector)\n        all_answers.append(answer)\n    \n    X = np.array(all_feats)\n    y = np.array(all_answers)\n    \n    wandb.config.update({\n        \"feature_dim\": X.shape[1],\n        \"n_features\": X.shape[1]\n    })\n    \n    # K-Fold training\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    \n    for fold_idx, (t_idx, v_idx) in enumerate(kf.split(X)):\n        m = lgb.LGBMRegressor(\n            n_estimators=50, \n            learning_rate=0.1, \n            verbose=-1,\n            objective='regression',\n            metric='mae'\n        )\n        m.fit(X[t_idx], y[t_idx], eval_set=[(X[v_idx], y[v_idx])])\n        LGB_MODELS.append(m)\n        \n        # Validation metrics\n        val_preds = m.predict(X[v_idx])\n        val_preds = np.clip(np.round(val_preds), 0, 9).astype(int)  # Single digit\n        val_mae = np.mean(np.abs(val_preds - y[v_idx]))\n        val_accuracy = np.mean(val_preds == y[v_idx])\n        \n        wandb.log({\n            f\"fold_{fold_idx}_mae\": val_mae,\n            f\"fold_{fold_idx}_accuracy\": val_accuracy\n        })\n    \n    wandb.log({\n        \"n_models\": len(LGB_MODELS),\n        \"training_status\": \"completed\"\n    })\n\n# ========== METHOD 5: PREDICTION WITH REASONING ==========\ndef predict_with_reasoning(problem_id, problem_text):\n    \"\"\"\n    METHOD: Two-stage prediction with detailed reasoning\n    REASONING:\n    Stage 1: Try symbolic solver (fast, accurate for structured problems)\n    Stage 2: If symbolic fails, use ML ensemble (learned from practice set)\n    \n    Returns: (answer, reasoning_string)\n    \"\"\"\n    # Check cache\n    h = hashlib.md5(problem_text.encode()).hexdigest()\n    if h in MEMO:\n        return MEMO[h][0], MEMO[h][1]\n    \n    # Stage 1: Symbolic solving\n    ans, method = solve_with_reasoning(problem_text)\n    \n    if ans is not None:\n        reasoning = f\"Symbolic solver ({method}): Direct mathematical computation\"\n        MEMO[h] = (ans, reasoning)\n        return ans, reasoning\n    \n    # Stage 2: ML ensemble\n    vec = ENGINE.get_reasoning_vector(problem_text)\n    log_f = list(extract_logical_features(problem_text).values())\n    feat = np.concatenate([vec, log_f]).reshape(1, -1)\n    \n    # Ensemble prediction\n    preds = np.mean([m.predict(feat) for m in LGB_MODELS], axis=0)\n    ans = int(np.clip(np.round(preds[0]), 0, 9))  # Single digit\n    \n    # Generate reasoning\n    domain = \"unknown\"\n    if log_f[0] > 0: domain = \"modulo\"\n    elif log_f[1] > 0: domain = \"geometry\"\n    elif log_f[2] > 0: domain = \"algebra\"\n    \n    reasoning = f\"ML ensemble: Learned pattern from practice set (domain={domain}, complexity={log_f[3]:.1f} tokens, raw_pred={preds[0]:.2f})\"\n    MEMO[h] = (ans, reasoning)\n    \n    return ans, reasoning\n\n# ========== PREDICTION API (for inference server) ==========\ndef predict(id_series: pl.Series, prob_series: pl.Series) -> pl.DataFrame:\n    \"\"\"Main prediction function called by inference server.\"\"\"\n    pid = id_series.item(0)\n    prob_text = prob_series.item(0)\n    \n    gc.collect()\n    if torch.cuda.is_available(): \n        torch.cuda.empty_cache()\n\n    ans, reasoning = predict_with_reasoning(pid, prob_text)\n    \n    # Log reasoning\n    REASONING_LOG.append({\n        \"id\": pid,\n        \"answer\": ans,\n        \"reasoning\": reasoning\n    })\n    \n    wandb.log({\n        \"prediction\": ans,\n        \"problem_id\": pid\n    })\n    \n    return pl.DataFrame({'id': [pid], 'answer': [ans]})\n\n# ========== MAIN EXECUTION ==========\nif __name__ == \"__main__\":\n    print(\"=\" * 80)\n    print(\"AI MATHEMATICAL OLYMPIAD - OFFLINE LEARNING SYSTEM\")\n    print(\"=\" * 80)\n    \n    # Step 1: Train from practice set\n    print(\"\\n[STEP 1] Training ensemble models from practice set...\")\n    train_ensemble()\n    print(f\"✅ Trained {len(LGB_MODELS)} models\")\n    \n    # Step 2: Load test questions\n    print(\"\\n[STEP 2] Loading test questions...\")\n    if os.path.exists(TEST_DATA_PATH):\n        test_df = pd.read_csv(TEST_DATA_PATH)\n        print(f\"✅ Loaded {len(test_df)} test questions\")\n        wandb.config.update({\"test_samples\": len(test_df)})\n    else:\n        print(\"⚠️ Test file not found, will use inference server\")\n        test_df = None\n    \n    # Step 3: Generate predictions for test set (if available)\n    if test_df is not None:\n        print(\"\\n[STEP 3] Generating predictions for test questions...\")\n        predictions = []\n        \n        for idx, row in test_df.iterrows():\n            pid = row['id']\n            prob_text = row['problem'] if 'problem' in row else str(row)\n            \n            ans, reasoning = predict_with_reasoning(pid, prob_text)\n            predictions.append({\n                'id': pid,\n                'answer': ans,\n                'reasoning': reasoning\n            })\n            \n            if (idx + 1) % 10 == 0:\n                print(f\"  Processed {idx + 1}/{len(test_df)} questions\")\n        \n        # Step 4: Create submission.csv (LAST STEP)\n        print(\"\\n[STEP 4] Creating submission.csv...\")\n        submission_df = pd.DataFrame({\n            'id': [p['id'] for p in predictions],\n            'answer': [p['answer'] for p in predictions]\n        })\n        \n        # Ensure all answers are single digits (0-9)\n        submission_df['answer'] = submission_df['answer'].clip(0, 9).astype(int)\n        \n        # Save submission file\n        submission_df.to_csv(\"submission.csv\", index=False)\n        print(f\"✅ Created submission.csv with {len(submission_df)} predictions\")\n        print(f\"   Answer range: {submission_df['answer'].min()} - {submission_df['answer'].max()}\")\n        \n        # Save reasoning log\n        reasoning_df = pd.DataFrame(predictions)\n        reasoning_df.to_csv(\"reasoning_log.csv\", index=False)\n        print(\"✅ Saved reasoning log to reasoning_log.csv\")\n        \n        # Log to WandB\n        wandb.save(\"submission.csv\")\n        wandb.save(\"reasoning_log.csv\")\n        \n        # Display sample predictions\n        print(\"\\n[STEP 5] Sample predictions:\")\n        print(submission_df.head(10).to_string(index=False))\n    \n    # Step 6: Start inference server (for competition evaluation)\n    print(\"\\n[STEP 6] Starting inference server for competition evaluation...\")\n    print(\"   Server will handle 50 questions per run (2 runs = 100 total)\")\n    \n    server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n    wandb.log({\"server_status\": \"started\"})\n    \n    try:\n        server.serve()\n    except KeyboardInterrupt:\n        wandb.log({\"server_status\": \"stopped\"})\n    finally:\n        # Finalize\n        wandb.log({\n            \"memo_size\": len(MEMO),\n            \"n_lgb_models\": len(LGB_MODELS),\n            \"engine_ready\": ENGINE.ready\n        })\n        \n        wandb.finish()\n        print(\"\\n✅ WandB run completed (offline mode)\")\n        print(f\"✅ Cached {len(MEMO)} solutions\")\n        print(\"✅ Submission file ready: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T03:28:12.085497Z","iopub.execute_input":"2026-01-14T03:28:12.086189Z","iopub.status.idle":"2026-01-14T03:40:37.908730Z","shell.execute_reply.started":"2026-01-14T03:28:12.086154Z","shell.execute_reply":"2026-01-14T03:40:37.907391Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/AIMO3_Reference_Problems.pdf\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/sample_submission.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/aimo_3_inference_server.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/aimo_3_gateway.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/__init__.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/templates.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/relay.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/__init__.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/generated/__init__.py\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__results__.html\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission_2.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__resultx__.html\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__notebook__.ipynb\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/__output__.json\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/submission_1.csv\n/kaggle/input/all-minilm-l6-v2-tuning-model-add/custom.css\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/reference.csv\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/submission.parquet\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__results__.html\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/vllm_server.log\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__notebook__.ipynb\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/__output__.json\n/kaggle/input/39-50-gpt-oss-120b-tir-dynamictime-out-pooling/custom.css\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1757436941.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# ========== WANDB INITIALIZATION ==========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Initialize WandB to track experiments, metrics, and model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m wandb.init(\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ai-mathematical-olympiad-progress-prize-3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     config={\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_run_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36mmaybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         wandb_login._login(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, referrer, update_api_key, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mkey_is_pre_configured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    236\u001b[0m     ) -> Tuple[Optional[str], ApiKeyStatus]:\n\u001b[1;32m    237\u001b[0m         \u001b[0;34m\"\"\"Updates the global API key by prompting the user.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             directive = (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local, referrer)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"google.colab\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mlog_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOG_STRING_NOCOLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattempt_colab_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_url\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_login\u001b[0;34m(app_url, referrer)\u001b[0m\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_wandbApiKey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3}]}